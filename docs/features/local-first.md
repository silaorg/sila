# Local-first by default

Sila was built to run without a server. Everything happens on your machine, so your data stays private and available even without an internet connection. This local-first setup keeps responses fast and lets you run local models for offline inference when you need it.

## Work offline, sync later

You can continue chatting, editing messages, and attaching files while offline. When your device reconnects or your cloud folder syncs, Sila merges the changes. There is no waiting for remote services or risk of losing work when a provider goes down.

## Your cloud, your choice

If you want to keep workspaces on multiple devices, store them in a folder synced by iCloud, Dropbox, Google Drive, or a similar service. Sila never sends your data to our servers. Only the services you choose see your files.

## A different philosophy from ChatGPT

ChatGPT relies on central servers to store and process everything. Sila lets you own the environment. You get the convenience of modern AI tools without giving up control of your information.

This local-first approach addresses the core issues with centralized AI platforms. Learn more about [the problems with ChatGPT](../the-problem-with-chatgpt.md) and why [owning your data](../own.md) matters.
